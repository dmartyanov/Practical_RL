{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Crossentropy method\n",
    "\n",
    "In this section we'll extend your CEM implementation with neural networks! You will train a multi-layer neural network to solve simple continuous state space games. __Please make sure you're done with tabular crossentropy method from the previous notebook.__\n",
    "\n",
    "![img](https://tip.duke.edu/independent_learning/greek/lesson/digging_deeper_final.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Google Colab, uncomment this:\n",
    "# !wget https://bit.ly/2FMJP5K -O setup.py && bash setup.py\n",
    "\n",
    "# XVFB will be launched if you run on a server\n",
    "import os\n",
    "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
    "    !bash ../xvfb start\n",
    "    os.environ['DISPLAY'] = ':1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state vector dim = 4\n",
      "n_actions = 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# if you see \"<classname> has no attribute .env\", remove .env or update gym\n",
    "env = gym.make(\"CartPole-v0\").env\n",
    "\n",
    "env.reset()\n",
    "n_actions = env.action_space.n\n",
    "state_dim = env.observation_space.shape[0]\n",
    "\n",
    "plt.imshow(env.render(\"rgb_array\"))\n",
    "print(\"state vector dim =\", state_dim)\n",
    "print(\"n_actions =\", n_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(20, 20), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=2, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=True)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "agent = MLPClassifier(\n",
    "    hidden_layer_sizes=(20, 20),\n",
    "    activation='tanh',\n",
    "    warm_start=True,\n",
    "    max_iter=2\n",
    ")\n",
    "\n",
    "# initialize agent to the dimension of state space and number of actions\n",
    "agent.partial_fit([env.reset()] * n_actions, range(n_actions), range(n_actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33189276, 0.66810724])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.predict_proba([[ 0.04076579,  0.15259605,  0.01352642, -0.33232651]]).reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 4\n",
    "hidden_sizes = [20, 100, 20]\n",
    "output_size = 2\n",
    "\n",
    "torch_agent = nn.Sequential(\n",
    "                    nn.Linear(input_size, hidden_sizes[0]),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(hidden_sizes[1], hidden_sizes[2]),\n",
    "                    nn.Tanh(),\n",
    "                    nn.Linear(hidden_sizes[2], output_size),\n",
    "                    nn.Softmax(dim=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of Sequential(\n",
      "  (0): Linear(in_features=4, out_features=20, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=20, out_features=100, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=100, out_features=20, bias=True)\n",
      "  (5): Tanh()\n",
      "  (6): Linear(in_features=20, out_features=2, bias=True)\n",
      "  (7): Softmax(dim=1)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "print(torch_agent.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_session(agent, predict, t_max=1000):\n",
    "    \"\"\"\n",
    "    Play a single game using agent neural network.\n",
    "    Terminate when game finishes or after :t_max: steps\n",
    "    \"\"\"\n",
    "    states, actions = [], []\n",
    "    total_reward = 0\n",
    "\n",
    "    s = env.reset()\n",
    "\n",
    "    for t in range(t_max):\n",
    "        \n",
    "        # use agent to predict a vector of action probabilities for state :s:\n",
    "#         probs = agent(torch.from_numpy(np.array([s])).float())\n",
    "#         probs = probs.detach().numpy()[0]\n",
    "        probs = predict(agent, s)\n",
    "\n",
    "        assert probs.shape == (n_actions,), \"make sure probabilities are a vector (hint: np.reshape)\"\n",
    "        \n",
    "        # use the probabilities you predicted to pick an action\n",
    "        # sample proportionally to the probabilities, don't just take the most likely action\n",
    "        a = np.random.choice(2, p=probs)\n",
    "        # ^-- hint: try np.random.choice\n",
    "\n",
    "        new_s, r, done, info = env.step(a)\n",
    "\n",
    "        # record sessions like you did before\n",
    "        states.append(s)\n",
    "        actions.append(a)\n",
    "        total_reward += r\n",
    "\n",
    "        s = new_s\n",
    "        if done:\n",
    "            break\n",
    "    return states, actions, total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_predict(agent, s):\n",
    "    probs = agent(torch.from_numpy(np.array([s])).float())\n",
    "    probs = probs.detach().numpy().reshape(-1)\n",
    "    return probs\n",
    "\n",
    "def mlp_predict(agent, s):\n",
    "    probs = agent.predict_proba([s]).reshape(-1)\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "states: [[-0.02531717 -0.02582489  0.00444392 -0.02054276]\n",
      " [-0.02583367  0.16923305  0.00403307 -0.31182027]\n",
      " [-0.02244901  0.36429731 -0.00220334 -0.60322857]\n",
      " [-0.01516306  0.55945001 -0.01426791 -0.89660469]\n",
      " [-0.00397406  0.75476246 -0.0322     -1.19373816]]\n",
      "actions: [1, 1, 1, 1, 1]\n",
      "reward: 5.0\n"
     ]
    }
   ],
   "source": [
    "dummy_states, dummy_actions, dummy_reward = generate_session(torch_agent, torch_predict, t_max=5)\n",
    "print(\"states:\", np.stack(dummy_states))\n",
    "print(\"actions:\", dummy_actions)\n",
    "print(\"reward:\", dummy_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "states: [[ 0.04433035  0.03052258 -0.03603899  0.02547136]\n",
      " [ 0.04494081  0.22614233 -0.03552956 -0.2783609 ]\n",
      " [ 0.04946365  0.42175265 -0.04109678 -0.5820347 ]\n",
      " [ 0.05789871  0.61742558 -0.05273748 -0.88737533]\n",
      " [ 0.07024722  0.81322216 -0.07048498 -1.1961595 ]]\n",
      "actions: [1, 1, 1, 1, 0]\n",
      "reward: 5.0\n"
     ]
    }
   ],
   "source": [
    "dummy_states, dummy_actions, dummy_reward = generate_session(agent, mlp_predict, t_max=5)\n",
    "print(\"states:\", np.stack(dummy_states))\n",
    "print(\"actions:\", dummy_actions)\n",
    "print(\"reward:\", dummy_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CEM steps\n",
    "Deep CEM uses exactly the same strategy as the regular CEM, so you can copy your function code from previous notebook.\n",
    "\n",
    "The only difference is that now each observation is not a number but a `float32` vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_elites(states_batch, actions_batch, rewards_batch, percentile=50):\n",
    "    \"\"\"\n",
    "    Select states and actions from games that have rewards >= percentile\n",
    "    :param states_batch: list of lists of states, states_batch[session_i][t]\n",
    "    :param actions_batch: list of lists of actions, actions_batch[session_i][t]\n",
    "    :param rewards_batch: list of rewards, rewards_batch[session_i]\n",
    "\n",
    "    :returns: elite_states,elite_actions, both 1D lists of states and respective actions from elite sessions\n",
    "\n",
    "    Please return elite states and actions in their original order \n",
    "    [i.e. sorted by session number and timestep within session]\n",
    "\n",
    "    If you are confused, see examples below. Please don't assume that states are integers\n",
    "    (they will become different later).\n",
    "    \"\"\"\n",
    "\n",
    "    reward_threshold = np.percentile(rewards_batch, percentile)\n",
    "\n",
    "    elite_states = \\\n",
    "        np.array([np.array(states_batch[i]) for i in range(len(rewards_batch)) if rewards_batch[i] >= reward_threshold])\n",
    "    elite_actions = \\\n",
    "        np.array([np.array(actions_batch[i]) for i in range(len(rewards_batch)) if rewards_batch[i] >= reward_threshold])\n",
    "    \n",
    "    elite_states = np.concatenate(elite_states)\n",
    "    elite_actions = np.concatenate(elite_actions)\n",
    "\n",
    "    return elite_states, elite_actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop\n",
    "Generate sessions, select N best and fit to those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "def show_progress(rewards_batch, log, percentile, reward_range=[-990, +10]):\n",
    "    \"\"\"\n",
    "    A convenience function that displays training progress. \n",
    "    No cool math here, just charts.\n",
    "    \"\"\"\n",
    "\n",
    "    mean_reward = np.mean(rewards_batch)\n",
    "    threshold = np.percentile(rewards_batch, percentile)\n",
    "    log.append([mean_reward, threshold])\n",
    "\n",
    "    clear_output(True)\n",
    "    print(\"mean reward = %.3f, threshold=%.3f\" % (mean_reward, threshold))\n",
    "    plt.figure(figsize=[8, 4])\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(list(zip(*log))[0], label='Mean rewards')\n",
    "    plt.plot(list(zip(*log))[1], label='Reward thresholds')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(rewards_batch, range=reward_range)\n",
    "    plt.vlines([np.percentile(rewards_batch, percentile)],\n",
    "               [0], [100], label=\"percentile\", color='red')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5908796  0.4091204 ]\n",
      " [0.5930116  0.40698844]\n",
      " [0.59103525 0.4089647 ]\n",
      " ...\n",
      " [0.59420574 0.40579426]\n",
      " [0.5955537  0.40444627]\n",
      " [0.596608   0.40339196]] [1 0 0 ... 0 0 0] 0.6843788027763367\n",
      "[[0.59097356 0.4090264 ]\n",
      " [0.59310603 0.40689403]\n",
      " [0.5911292  0.40887076]\n",
      " ...\n",
      " [0.5943012  0.40569884]\n",
      " [0.5956501  0.40434995]\n",
      " [0.596705   0.40329495]] [1 0 0 ... 0 0 0] 0.6843740344047546\n",
      "[[0.5907701  0.40922987]\n",
      " [0.5902556  0.40974435]\n",
      " [0.59015316 0.40984687]\n",
      " ...\n",
      " [0.5910762  0.40892383]\n",
      " [0.59161514 0.40838492]\n",
      " [0.59312147 0.40687856]] [0 0 0 ... 0 0 1] 0.6840682625770569\n",
      "[[0.5910603  0.40893975]\n",
      " [0.59054387 0.4094561 ]\n",
      " [0.5904406  0.4095594 ]\n",
      " ...\n",
      " [0.591366   0.408634  ]\n",
      " [0.59190536 0.40809467]\n",
      " [0.59341145 0.40658855]] [0 0 0 ... 0 0 1] 0.6840524673461914\n",
      "[[0.59185183 0.40814826]\n",
      " [0.59358966 0.40641037]\n",
      " [0.5916603  0.40833968]\n",
      " ...\n",
      " [0.59389293 0.406107  ]\n",
      " [0.59550494 0.40449503]\n",
      " [0.59686255 0.40313742]] [1 0 1 ... 0 0 0] 0.6824867129325867\n",
      "[[0.59238464 0.40761533]\n",
      " [0.5941282  0.40587184]\n",
      " [0.59219307 0.4078069 ]\n",
      " ...\n",
      " [0.5944142  0.40558577]\n",
      " [0.59602773 0.4039723 ]\n",
      " [0.5973876  0.40261242]] [1 0 1 ... 0 0 0] 0.682449996471405\n",
      "[[0.5916278  0.40837222]\n",
      " [0.593344   0.406656  ]\n",
      " [0.5914542  0.4085458 ]\n",
      " ...\n",
      " [0.59319216 0.40680784]\n",
      " [0.5926594  0.40734056]\n",
      " [0.59285575 0.40714425]] [1 0 1 ... 1 1 0] 0.6825827956199646\n",
      "[[0.59243643 0.40756363]\n",
      " [0.5941624  0.4058376 ]\n",
      " [0.5922628  0.40773717]\n",
      " ...\n",
      " [0.5939804  0.4060196 ]\n",
      " [0.5934563  0.40654364]\n",
      " [0.59365845 0.40634158]] [1 0 1 ... 1 1 0] 0.6825296878814697\n",
      "[[0.59257185 0.40742812]\n",
      " [0.5913892  0.40861085]\n",
      " [0.59131354 0.4086865 ]\n",
      " ...\n",
      " [0.59486836 0.40513167]\n",
      " [0.5962429  0.40375715]\n",
      " [0.59766394 0.4023361 ]] [0 0 1 ... 0 0 1] 0.6839070320129395\n",
      "[[0.5936212  0.40637884]\n",
      " [0.59242284 0.40757716]\n",
      " [0.5923375  0.4076625 ]\n",
      " ...\n",
      " [0.59586865 0.40413138]\n",
      " [0.59724236 0.4027576 ]\n",
      " [0.59866375 0.4013363 ]] [0 0 1 ... 0 0 1] 0.6838530898094177\n",
      "[[0.59321624 0.40678373]\n",
      " [0.59240144 0.4075986 ]\n",
      " [0.5922293  0.40777072]\n",
      " ...\n",
      " [0.59392834 0.4060717 ]\n",
      " [0.59447205 0.405528  ]\n",
      " [0.595734   0.40426594]] [0 0 0 ... 0 0 1] 0.6839947700500488\n",
      "[[0.59447193 0.40552807]\n",
      " [0.59363663 0.40636337]\n",
      " [0.593451   0.40654904]\n",
      " ...\n",
      " [0.59515834 0.40484163]\n",
      " [0.59569734 0.40430257]\n",
      " [0.596944   0.403056  ]] [0 0 0 ... 0 0 1] 0.6839345097541809\n",
      "[[0.5948576  0.40514237]\n",
      " [0.59707916 0.40292084]\n",
      " [0.5998538  0.40014622]\n",
      " ...\n",
      " [0.5951934  0.40480658]\n",
      " [0.5967023  0.40329766]\n",
      " [0.5976902  0.40230978]] [1 1 1 ... 0 0 0] 0.6778715252876282\n",
      "[[0.5964296  0.40357038]\n",
      " [0.5986751  0.40132496]\n",
      " [0.60147065 0.3985293 ]\n",
      " ...\n",
      " [0.59672153 0.40327847]\n",
      " [0.5982125  0.40178752]\n",
      " [0.599197   0.40080303]] [1 1 1 ... 0 0 0] 0.6776994466781616\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-180-f34743897b8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# generate new sessions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0msessions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgenerate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_predict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_sessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mstates_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-180-f34743897b8e>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# generate new sessions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0msessions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgenerate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_predict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_sessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mstates_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-174-b66ed273ee05>\u001b[0m in \u001b[0;36mgenerate_session\u001b[0;34m(agent, predict, t_max)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# use the probabilities you predicted to pick an action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# sample proportionally to the probabilities, don't just take the most likely action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;31m# ^-- hint: try np.random.choice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_sessions = 100\n",
    "percentile = 30\n",
    "log = []\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "learning_rate = 1e-2\n",
    "optimizer = torch.optim.LBFGS(torch_agent.parameters(), max_iter=2, lr=learning_rate)\n",
    "optimizer.zero_grad()\n",
    "\n",
    "def closure():\n",
    "    y_pred = torch_agent(X.float())\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    loss.backward()\n",
    "    print('{} {} {}'.format(y_pred.detach().numpy(), y.detach().numpy(), loss.detach()))\n",
    "    return loss\n",
    "    \n",
    "for i in range(100):\n",
    "    # generate new sessions\n",
    "    sessions = list([generate_session(torch_agent, torch_predict, t_max=1000) for _ in range(n_sessions)])\n",
    "\n",
    "    states_batch, actions_batch, rewards_batch = map(np.array, zip(*sessions))\n",
    "\n",
    "    elite_states, elite_actions = select_elites(states_batch, \\\n",
    "                                                actions_batch, rewards_batch, percentile)\n",
    "\n",
    "    X = torch.from_numpy(elite_states)\n",
    "    y = torch.from_numpy(elite_actions)\n",
    "\n",
    "    optimizer.step(closure)\n",
    "    \n",
    "\n",
    "#     show_progress(rewards_batch, log, percentile, reward_range=[0, np.max(rewards_batch)])\n",
    "\n",
    "    if np.mean(rewards_batch) > 190:\n",
    "        print(\"You Win! Will be stopped\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean reward = 198.570, threshold=161.400\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You Win! Will be stopped\n"
     ]
    }
   ],
   "source": [
    "n_sessions = 100\n",
    "percentile = 30\n",
    "log = []\n",
    "\n",
    "for i in range(100):\n",
    "    # generate new sessions\n",
    "    sessions = list([generate_session(agent, mlp_predict, t_max=1000) for _ in range(n_sessions)])\n",
    "\n",
    "    states_batch, actions_batch, rewards_batch = map(np.array, zip(*sessions))\n",
    "\n",
    "    elite_states, elite_actions = select_elites(states_batch, \\\n",
    "                                                actions_batch, rewards_batch, percentile)\n",
    "        \n",
    "    agent.partial_fit(elite_states, elite_actions)\n",
    "\n",
    "    show_progress(rewards_batch, log, percentile, reward_range=[0, np.max(rewards_batch)])\n",
    "\n",
    "    if np.mean(rewards_batch) > 190:\n",
    "        print(\"You Win! Will be stopped\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm videos/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# record sessions\n",
    "import gym.wrappers\n",
    "env = gym.wrappers.Monitor(gym.make(\"CartPole-v0\"),\n",
    "                           directory=\"videos\", force=True)\n",
    "sessions = [generate_session(agent, mlp_predict) for _ in range(100)]\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"640\" height=\"480\" controls>\n",
       "  <source src=\"./videos/openaigym.video.2.14699.video000001.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show video\n",
    "from IPython.display import HTML\n",
    "import os\n",
    "\n",
    "video_names = list(\n",
    "    filter(lambda s: s.endswith(\".mp4\"), os.listdir(\"./videos/\")))\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"{}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\".format(\"./videos/\"+video_names[-1]))  # this may or may not be _last_ video. Try other indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework part I\n",
    "\n",
    "### Tabular crossentropy method\n",
    "\n",
    "You may have noticed that the taxi problem quickly converges from -100 to a near-optimal score and then descends back into -50/-100. This is in part because the environment has some innate randomness. Namely, the starting points of passenger/driver change from episode to episode.\n",
    "\n",
    "### Tasks\n",
    "- __1.1__ (1 pts) Find out how the algorithm performance changes if you use a different `percentile` and/or `n_sessions`.\n",
    "- __1.2__ (2 pts) Tune the algorithm to end up with positive average score.\n",
    "\n",
    "It's okay to modify the existing code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```<Describe what you did here.  Preferably with plot/report to support it.>```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework part II\n",
    "\n",
    "### Deep crossentropy method\n",
    "\n",
    "By this moment you should have got enough score on [CartPole-v0](https://gym.openai.com/envs/CartPole-v0) to consider it solved (see the link). It's time to try something harder.\n",
    "\n",
    "* if you have any trouble with CartPole-v0 and feel stuck, feel free to ask us or your peers for help.\n",
    "\n",
    "### Tasks\n",
    "\n",
    "* __2.1__ (3 pts) Pick one of environments: MountainCar-v0 or LunarLander-v2.\n",
    "  * For MountainCar, get average reward of __at least -150__\n",
    "  * For LunarLander, get average reward of __at least +50__\n",
    "\n",
    "See the tips section below, it's kinda important.\n",
    "__Note:__ If your agent is below the target score, you'll still get most of the points depending on the result, so don't be afraid to submit it.\n",
    "  \n",
    "  \n",
    "* __2.2__ (bonus: 4++ pt) Devise a way to speed up training at least 2x against the default version\n",
    "  * Obvious improvement: use [joblib](https://www.google.com/search?client=ubuntu&channel=fs&q=joblib&ie=utf-8&oe=utf-8)\n",
    "  * Try re-using samples from 3-5 last iterations when computing threshold and training\n",
    "  * Experiment with amount of training iterations and learning rate of the neural network (see params)\n",
    "  * __Please list what you did in anytask submission form__\n",
    "  \n",
    "  \n",
    "### Tips\n",
    "* Gym page: [MountainCar](https://gym.openai.com/envs/MountainCar-v0), [LunarLander](https://gym.openai.com/envs/LunarLander-v2)\n",
    "* Sessions for MountainCar may last for 10k+ ticks. Make sure ```t_max``` param is at least 10k.\n",
    " * Also it may be a good idea to cut rewards via \">\" and not \">=\". If 90% of your sessions get reward of -10k and 20% are better, than if you use percentile 20% as threshold, R >= threshold __fails cut off bad sessions__ whule R > threshold works alright.\n",
    "* _issue with gym_: Some versions of gym limit game time by 200 ticks. This will prevent cem training in most cases. Make sure your agent is able to play for the specified __t_max__, and if it isn't, try `env = gym.make(\"MountainCar-v0\").env` or otherwise get rid of TimeLimit wrapper.\n",
    "* If you use old _swig_ lib for LunarLander-v2, you may get an error. See this [issue](https://github.com/openai/gym/issues/100) for solution.\n",
    "* If it won't train it's a good idea to plot reward distribution and record sessions: they may give you some clue. If they don't, call course staff :)\n",
    "* 20-neuron network is probably not enough, feel free to experiment.\n",
    "\n",
    "You may find the following snippet useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_mountain_car(env, agent):\n",
    "    xs = np.linspace(env.min_position, env.max_position, 100)\n",
    "    vs = np.linspace(-env.max_speed, env.max_speed, 100)\n",
    "    grid = np.dstack(np.meshgrid(xs, vs)).transpose(1, 0, 2)\n",
    "    grid_flat = grid.reshape(len(xs) * len(vs), 2)\n",
    "    probs = agent.predict_proba(grid_flat).reshape(len(xs), len(vs), 3)\n",
    "    return probs\n",
    "\n",
    "plt.imshow(visualize_mountain_car(env, agent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus tasks\n",
    "\n",
    "* __2.3 bonus__ Try to find a network architecture and training params that solve __both__ environments above (_Points depend on implementation. If you attempted this task, please mention it in anytask submission._)\n",
    "\n",
    "* __2.4 bonus__ Solve continuous action space task with `MLPRegressor` or similar.\n",
    "  * Start with [\"Pendulum-v0\"](https://github.com/openai/gym/wiki/Pendulum-v0).\n",
    "  * Since your agent only predicts the \"expected\" action, you will have to add noise to ensure exploration.\n",
    "  * [MountainCarContinuous-v0](https://gym.openai.com/envs/MountainCarContinuous-v0), [LunarLanderContinuous-v2](https://gym.openai.com/envs/LunarLanderContinuous-v2) \n",
    "  * 4 points for solving. Slightly less for getting some results below solution threshold. Note that discrete and continuous environments may have slightly different rules aside from action spaces.\n",
    "\n",
    "\n",
    "If you're still feeling unchallenged, consider the project (see other notebook in this folder)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
